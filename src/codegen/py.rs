use crate::ast::{Query, QueryFile};
use crate::schema::{Column, Index, Partition, Schema, Table, TableConstraint};

pub fn generate_py(query_file: &QueryFile, schema: Option<&Schema>) -> String {
    let mut output = String::new();

    output.push_str("# Auto-generated Python types and functions\n");
    output.push_str("# Generated by Stratus TypeSQL Compiler (PostgreSQL)\n\n");

    output.push_str("from typing import Any, Dict, List, Optional, Union\n");
    output.push_str("from dataclasses import dataclass, field\n");
    output.push_str("from datetime import datetime, date, time, timedelta\n");
    output.push_str("import uuid\n\n");

    // Generate schema-based types
    if let Some(schema) = schema {
        output.push_str("# ==================== Schema Types ====================\n\n");

        for (table_name, table) in &schema.tables {
            let class_name = to_pascal_case(table_name);
            output.push_str(&format!("# Table: {}\n", table_name));
            output.push_str(&format!("@dataclass\n"));
            output.push_str(&format!("class {}:\n", class_name));

            for (col_name, col) in &table.columns {
                let py_type = map_sql_type_to_py(col);
                let default = get_py_default(col);
                let identity_marker = if col.identity.is_some() {
                    "  # identity"
                } else {
                    ""
                };
                let generated_marker = if col.generated.is_some() {
                    "  # generated"
                } else {
                    ""
                };
                output.push_str(&format!(
                    "    {}: {}{}{}\n",
                    col_name, py_type, default, identity_marker
                ));
            }
            output.push_str("\n");

            // Generate Insert class
            output.push_str(&format!("@dataclass\n"));
            output.push_str(&format!("class Insert{}:\n", class_name));
            output.push_str(&format!(
                "    pass  # All fields are optional for insert\n\n"
            ));
        }

        // Generate enums
        if let Some(enums) = &schema.enums {
            output.push_str("# ==================== Enums ====================\n\n");
            for (enum_name, values) in enums {
                let class_name = to_pascal_case(enum_name);
                output.push_str(&format!("class {}(str):\n", class_name));
                output.push_str(&format!("    \"\"\"Enum for {} values\"\"\"\n", enum_name));
                for (i, v) in values.iter().enumerate() {
                    output.push_str(&format!("    {} = {}  # {}\n", v.to_uppercase(), i, v));
                }
                output.push_str(&format!(
                    "    _VALUES = [{}]\n\n",
                    values
                        .iter()
                        .map(|v| format!("'{}'", v))
                        .collect::<Vec<_>>()
                        .join(", ")
                ));
            }
        }

        // Generate partitioned tables info
        let partitioned_tables: Vec<_> = schema
            .tables
            .iter()
            .filter(|(_, t)| !t.partitions.is_empty())
            .collect();
        if !partitioned_tables.is_empty() {
            output.push_str("# ==================== Partitioned Tables ====================\n\n");
            for (table_name, table) in partitioned_tables {
                let class_name = to_pascal_case(table_name);
                output.push_str(&format!("@dataclass\n"));
                output.push_str(&format!("class {}Partition:\n", class_name));
                output.push_str("    partition_name: str\n");
                output.push_str("    partition_values: str\n\n");
            }
        }
    }

    // Generate query parameter types
    output.push_str("# ==================== Query Parameters ====================\n\n");
    for query in &query_file.queries {
        let class_name = format!("{}Params", query.name);
        output.push_str(&format!("@dataclass\n"));
        output.push_str(&format!("class {}:\n", class_name));
        if query.params.is_empty() {
            output.push_str("    pass\n\n");
        } else {
            for param in &query.params {
                let py_type = map_param_type_to_py(&param.type_);
                output.push_str(&format!("    {}: {}\n", param.name, py_type));
            }
            output.push_str("\n");
        }
    }

    // Generate query result types
    output.push_str("# ==================== Query Results ====================\n\n");
    for query in &query_file.queries {
        // Use JOIN-aware type generation
        if let Some(schema) = schema {
            let result_class = generate_py_query_result_class(&query.name, &query.sql, schema);
            output.push_str(&result_class);
        } else {
            let class_name = format!("{}Result", query.name);
            output.push_str(&format!("@dataclass\n"));
            output.push_str(&format!("class {}:\n", class_name));
            output.push_str("    pass  # Schema required for type inference\n\n");
        }
    }

    // Generate query registry
    output.push_str("# ==================== Query Registry ====================\n\n");
    output.push_str("QUERIES: Dict[str, Dict[str, Any]] = {\n");
    for query in &query_file.queries {
        output.push_str(&format!("    \"{}\": {{\n", query.name));
        output.push_str(&format!(
            "        \"sql\": \"{}\",\n",
            query.sql.replace("\"", "\\\"")
        ));
        let params_tuple = if query.params.is_empty() {
            "()".to_string()
        } else {
            let params: Vec<_> = query
                .params
                .iter()
                .map(|p| format!("\"{}\"", p.name))
                .collect();
            format!("({})", params.join(", "))
        };
        output.push_str(&format!("        \"params\": {},\n", params_tuple));
        output.push_str(&format!("    }},\n"));
    }
    output.push_str("}\n\n");

    // Generate execute stub
    output.push_str("# ==================== Database Driver ====================\n\n");
    output.push_str("async def execute(query_name: str, sql: str, params: list) -> Any:\n");
    output.push_str("    \"\"\"Execute query - connect to your PostgreSQL driver\"\"\"\n");
    output.push_str("    # TODO: Connect to native PostgreSQL driver (asyncpg, psycopg2, etc.)\n");
    output.push_str("    raise NotImplementedError(\"Connect to PostgreSQL driver\")\n\n");

    // Generate type-safe query functions
    output.push_str("# ==================== Type-Safe Query Functions ====================\n\n");
    for query in &query_file.queries {
        let params_type = format!("{}Params", query.name);
        let return_type = format!("{}Result", query.name);
        let return_type_hint = if query.return_type == "many" {
            format!("List[{}]", return_type)
        } else {
            format!("Optional[{}]", return_type)
        };
        let func_name = to_snake_case(&query.name);

        output.push_str(&format!(
            "async def {}(params: {}) -> {}:\n",
            func_name, params_type, return_type_hint
        ));
        output.push_str(&format!(
            "    sql = \"{}\"\n",
            query.sql.replace("\"", "\\\"")
        ));

        if query.params.is_empty() {
            output.push_str("    return await execute(\"\", sql, [])\n");
        } else {
            output.push_str("    params_list = [\n");
            for param in &query.params {
                output.push_str(&format!(
                    "        params.{},  # ${}\n",
                    param.name, param.ordinal
                ));
            }
            output.push_str("    ]\n");
            output.push_str(&format!(
                "    return await execute(\"{}\", sql, params_list)\n",
                query.name
            ));
        }
        output.push_str("\n");
    }

    output
}

pub fn generate_py_types_only(schema: &Schema) -> String {
    let mut output = String::new();

    output.push_str("# Auto-generated Python types from PostgreSQL schema\n");
    output.push_str("# Generated by Stratus TypeSQL Compiler\n\n");

    output.push_str("from dataclasses import dataclass\n");
    output.push_str("from typing import Optional, List\n");
    output.push_str("from datetime import datetime, date, time, timedelta\n");
    output.push_str("import uuid\n\n");

    for (table_name, table) in &schema.tables {
        let class_name = to_pascal_case(table_name);
        output.push_str(&format!("# Table: {}\n", table_name));
        output.push_str(&format!("@dataclass\n"));
        output.push_str(&format!("class {}:\n", class_name));

        for (col_name, col) in &table.columns {
            let py_type = map_sql_type_to_py(col);
            let default = get_py_default(col);
            let identity_marker = if col.identity.is_some() {
                "  # identity"
            } else {
                ""
            };
            output.push_str(&format!(
                "    {}: {}{}{}\n",
                col_name, py_type, default, identity_marker
            ));
        }
        output.push_str("\n");

        // Generate Insert class
        output.push_str(&format!("@dataclass\n"));
        output.push_str(&format!("class Insert{}:\n", class_name));
        output.push_str(&format!("    pass\n\n"));
    }

    output
}

fn map_sql_type_to_py(col: &Column) -> String {
    let base_type = col.data_type.to_lowercase();
    let is_array = col.array_dimensions.is_some();

    let result = match base_type.as_str() {
        "serial" | "bigserial" | "integer" | "int" | "int4" | "int8" | "bigint" | "smallint" => {
            "int"
        }
        "float" | "double precision" | "real" | "decimal" | "numeric" => "float",
        "varchar" | "char" | "bpchar" | "text" => "str",
        "boolean" | "bool" => "bool",
        "date" => "date",
        "timestamp"
        | "timestamptz"
        | "timestamp with time zone"
        | "timestamp without time zone" => "datetime",
        "time" | "timetz" => "time",
        "interval" => "timedelta",
        "json" | "jsonb" => "Any",
        "uuid" => "uuid.UUID",
        "xml" => "str",
        "bytea" => "bytes",
        "cidr" | "inet" | "macaddr" | "macaddr8" => "str",
        "point" | "line" | "lseg" | "box" | "path" | "polygon" | "circle" => "str",
        "tsvector" => "str",
        "tsquery" => "str",
        "hstore" => "Dict[str, Any]",
        "ltree" => "str",
        "money" => "float",
        "any" | "anyelement" | "anyarray" | "anynonarray" | "anyenum" | "anyrange" => "Any",
        _ => "Any",
    };

    if is_array {
        format!("List[{}]", result)
    } else {
        result.to_string()
    }
}

fn map_param_type_to_py(sql_type: &str) -> &str {
    match sql_type.to_lowercase().as_str() {
        "number" | "int" | "integer" | "float" | "double" | "decimal" => "int",
        "text" | "string" | "varchar" | "char" => "str",
        "boolean" | "bool" => "bool",
        "date" | "timestamp" | "datetime" => "datetime",
        "json" => "Any",
        _ => "Any",
    }
}

fn get_py_default(col: &Column) -> String {
    if !col.is_not_null() && !col.is_primary_key() {
        return " = None".to_string();
    }
    if let Some(default_val) = &col.default {
        let val = default_val.trim();
        if val == "now()" || val == "current_timestamp" {
            return " = datetime.now()".to_string();
        }
        if val == "current_date" {
            return " = date.today()".to_string();
        }
        if val == "current_time" {
            return " = time()".to_string();
        }
        if val == "gen_random_uuid()" {
            return " = uuid.uuid4()".to_string();
        }
        if val.starts_with('\'') && val.ends_with('\'') {
            return format!(" = \"{}\"", &val[1..val.len() - 1]);
        }
        if val.parse::<f64>().is_ok() {
            return format!(" = {}", val);
        }
        if val == "true" || val == "false" {
            return format!(" = {}", val);
        }
    }
    String::new()
}

fn to_pascal_case(s: &str) -> String {
    let mut result = String::new();
    let mut capitalize = true;
    for c in s.chars() {
        if c == '_' {
            capitalize = true;
        } else if capitalize {
            result.push(c.to_ascii_uppercase());
            capitalize = false;
        } else {
            result.push(c);
        }
    }
    result
}

fn to_snake_case(name: &str) -> String {
    let mut result = String::new();
    for (i, c) in name.chars().enumerate() {
        if c.is_uppercase() {
            if i > 0 {
                result.push('_');
            }
            result.push(c.to_lowercase().to_string().chars().next().unwrap());
        } else {
            result.push(c);
        }
    }
    result
}

fn extract_table_from_query(sql: &str) -> Option<String> {
    let sql_lower = sql.to_lowercase();
    if let Some(from_pos) = sql_lower.find("from") {
        let after_from = &sql[from_pos + 4..];
        let tokens: Vec<&str> = after_from.split_whitespace().collect();
        if !tokens.is_empty() {
            let table = tokens[0].trim_matches(|c| c == '"' || c == '`' || c == '\'');
            return Some(table.to_string());
        }
    }
    None
}

/// Generate query result class with JOIN support
pub fn generate_py_query_result_class(query_name: &str, sql: &str, schema: &Schema) -> String {
    use crate::parser::{extract_select_columns, extract_tables_from_sql};

    let tables = extract_tables_from_sql(sql);
    let columns = extract_select_columns(sql);
    let class_name = format!("{}Result", query_name);

    // Track used property names to detect conflicts
    let mut used_property_names: std::collections::HashSet<String> =
        std::collections::HashSet::new();

    let mut result = format!("@dataclass\n");
    result.push_str(&format!("class {}:\n", class_name));

    if !tables.is_empty() && !columns.is_empty() {
        // Track full column path for deduplication
        let mut processed_columns: std::collections::HashSet<String> =
            std::collections::HashSet::new();

        for col in &columns {
            // Handle table.* wildcard
            if col.is_wildcard && col.table_name.is_some() {
                let table_name = col.table_name.as_ref().unwrap();
                if let Some(table) = schema.tables.get(table_name) {
                    for (col_name, column) in &table.columns {
                        let key = format!("{}.{}", table_name, col_name);
                        if !processed_columns.contains(&key) {
                            processed_columns.insert(key);
                            let py_type = map_sql_type_to_py(column);
                            let default = get_py_default(column);
                            let property_name = get_unique_property_name(
                                col_name,
                                table_name,
                                &mut used_property_names,
                            );
                            result.push_str(&format!("    # From {}\n", table_name));
                            result.push_str(&format!(
                                "    {}: {}{}\n",
                                property_name, py_type, default
                            ));
                        }
                    }
                }
            }
            // Handle * wildcard (all tables)
            else if col.is_wildcard && col.table_name.is_none() {
                for table_name in &tables {
                    if let Some(table) = schema.tables.get(table_name) {
                        for (col_name, column) in &table.columns {
                            let key = format!("{}.{}", table_name, col_name);
                            if !processed_columns.contains(&key) {
                                processed_columns.insert(key);
                                let py_type = map_sql_type_to_py(column);
                                let default = get_py_default(column);
                                let property_name = get_unique_property_name(
                                    col_name,
                                    table_name,
                                    &mut used_property_names,
                                );
                                result.push_str(&format!("    # From {}\n", table_name));
                                result.push_str(&format!(
                                    "    {}: {}{}\n",
                                    property_name, py_type, default
                                ));
                            }
                        }
                    }
                }
            }
            // Handle specific column (table.column or column)
            else {
                let table_name = col.table_name.clone().or_else(|| tables.first().cloned());

                if let Some(tname) = table_name {
                    if let Some(table) = schema.tables.get(&tname) {
                        if let Some(column) = table.columns.get(&col.column_name) {
                            let py_type = map_sql_type_to_py(column);
                            let default = get_py_default(column);
                            let property_name = get_unique_property_name(
                                &col.column_name,
                                &tname,
                                &mut used_property_names,
                            );
                            result.push_str(&format!("    # From {}\n", tname));
                            result.push_str(&format!(
                                "    {}: {}{}\n",
                                property_name, py_type, default
                            ));
                        } else {
                            // Column not found in schema
                            let property_name = get_unique_property_name(
                                &col.column_name,
                                &tname,
                                &mut used_property_names,
                            );
                            result.push_str(&format!(
                                "    # {} (unknown type)\n    {}: Any = None\n",
                                col.column_name, property_name
                            ));
                        }
                    } else {
                        // Table not found
                        let property_name = get_unique_property_name(
                            &col.column_name,
                            &tname,
                            &mut used_property_names,
                        );
                        result.push_str(&format!(
                            "    # {} (table not found)\n    {}: Any = None\n",
                            col.column_name, property_name
                        ));
                    }
                }
            }
        }
    } else if let Some(table_name) = tables.first() {
        if let Some(table) = schema.tables.get(table_name) {
            for (col_name, column) in &table.columns {
                let py_type = map_sql_type_to_py(column);
                let default = get_py_default(column);
                result.push_str(&format!("    {}: {}{}\n", col_name, py_type, default));
            }
        } else {
            result.push_str("    pass  # Table not found in schema\n");
        }
    } else {
        result.push_str("    pass  # Use schema to infer types\n");
    }

    result.push_str("\n");
    result
}

/// Get a unique property name, adding table prefix if there's a conflict
fn get_unique_property_name(
    column_name: &str,
    table_name: &str,
    used_names: &mut std::collections::HashSet<String>,
) -> String {
    let mut property_name = column_name.to_string();
    let mut counter = 1;

    while used_names.contains(&property_name) {
        // Conflict detected, use table prefix with counter
        property_name = format!("{}_{}_{}", table_name, column_name, counter);
        counter += 1;
    }

    used_names.insert(property_name.clone());
    property_name
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_to_pascal_case() {
        assert_eq!(to_pascal_case("users"), "Users");
        assert_eq!(to_pascal_case("user_posts"), "UserPosts");
    }

    #[test]
    fn test_to_snake_case() {
        assert_eq!(to_snake_case("GetUser"), "get_user");
        assert_eq!(to_snake_case("ListUsers"), "list_users");
    }

    #[test]
    fn test_get_unique_property_name_no_conflict() {
        let mut used = std::collections::HashSet::new();
        assert_eq!(get_unique_property_name("id", "users", &mut used), "id");
        assert!(used.contains("id"));
    }

    #[test]
    fn test_get_unique_property_name_with_conflict() {
        let mut used = std::collections::HashSet::new();
        used.insert("id".to_string());
        assert_eq!(
            get_unique_property_name("id", "orders", &mut used),
            "orders_id_1"
        );
        assert!(used.contains("orders_id_1"));
    }

    #[test]
    fn test_generate_py_query_result_class_with_join_conflicts() {
        use crate::schema::{Column, Schema, Table};

        let mut tables = std::collections::HashMap::new();
        let mut users_cols = std::collections::HashMap::new();
        users_cols.insert(
            "id".to_string(),
            Column {
                data_type: "integer".to_string(),
                ..Default::default()
            },
        );
        users_cols.insert(
            "email".to_string(),
            Column {
                data_type: "varchar".to_string(),
                ..Default::default()
            },
        );
        tables.insert(
            "users".to_string(),
            Table {
                columns: users_cols,
                ..Default::default()
            },
        );

        let mut orders_cols = std::collections::HashMap::new();
        orders_cols.insert(
            "id".to_string(),
            Column {
                data_type: "integer".to_string(),
                ..Default::default()
            },
        );
        orders_cols.insert(
            "user_id".to_string(),
            Column {
                data_type: "integer".to_string(),
                ..Default::default()
            },
        );
        orders_cols.insert(
            "total".to_string(),
            Column {
                data_type: "decimal".to_string(),
                ..Default::default()
            },
        );
        tables.insert(
            "orders".to_string(),
            Table {
                columns: orders_cols,
                ..Default::default()
            },
        );

        let schema = Schema {
            tables,
            ..Default::default()
        };

        let sql = "SELECT users.*, orders.* FROM users JOIN orders ON users.id = orders.user_id";
        let result = generate_py_query_result_class("GetUserWithOrders", sql, &schema);

        // Should have:
        // - id from users (no prefix, first occurrence)
        // - email from users (no prefix)
        // - user_id from orders (no prefix, not conflicting)
        // - total from orders (no prefix)
        // - orders_id_1 from orders (duplicate id gets prefix)
        assert!(result.contains("id: int"), "First id should be plain 'id'");
        assert!(
            result.contains("orders_id_1"),
            "Second id should be orders_id_1"
        );
        assert!(
            result.contains("email: str"),
            "Should have users.email as email"
        );
        assert!(
            result.contains("user_id: int"),
            "Should have orders.user_id as user_id"
        );
        assert!(
            result.contains("total: float"),
            "Should have orders.total as total"
        );
    }
}
